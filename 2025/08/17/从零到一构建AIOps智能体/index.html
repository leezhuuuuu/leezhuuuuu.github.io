<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="custom-style" content="&lt;style&gt;article .content, article .article-more-link { display: none !important"><title>从零到一构建AIOps智能体 - leezhuuuuu&#039;s blog</title><link rel="manifest" href="../../../../manifest.json"><meta name="application-name" content="leezhuuuuu&#039;s blog"><meta name="msapplication-TileImage" content="https://avatars.githubusercontent.com/u/178091611?v=4"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="leezhuuuuu&#039;s blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="写在前面：大家好。在近期为期三个月的实习中，我深度参与了大型语言模型（LLM）Agent的探索与实践。这篇文章，我想和大家分享我从零到一构建一个系统级智能Agent框架的心路历程。它不只是一篇技术教程，更是一次关于如何将LLM的强大推理能力，转化为稳定、可靠的工程能力的深度复盘。希望能给同样走在这条路上的你，带来一些启发。   第一部分：问题的本质 —— 我为什么要构建这个框架？ 故事的起点，可"><meta property="og:type" content="blog"><meta property="og:title" content="从零到一构建AIOps智能体"><meta property="og:url" content="https://leezhuuuuu.github.io/2025/08/17/%E4%BB%8E%E9%9B%B6%E5%88%B0%E4%B8%80%E6%9E%84%E5%BB%BAAIOps%E6%99%BA%E8%83%BD%E4%BD%93/"><meta property="og:site_name" content="leezhuuuuu&#039;s blog"><meta property="og:description" content="写在前面：大家好。在近期为期三个月的实习中，我深度参与了大型语言模型（LLM）Agent的探索与实践。这篇文章，我想和大家分享我从零到一构建一个系统级智能Agent框架的心路历程。它不只是一篇技术教程，更是一次关于如何将LLM的强大推理能力，转化为稳定、可靠的工程能力的深度复盘。希望能给同样走在这条路上的你，带来一些启发。   第一部分：问题的本质 —— 我为什么要构建这个框架？ 故事的起点，可"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://leezhuuuuu.github.io/img/og_image.png"><meta property="article:published_time" content="2025-08-17T14:00:00.000Z"><meta property="article:modified_time" content="2025-08-18T14:58:57.839Z"><meta property="article:author" content="leezhuuuuu"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://leezhuuuuu.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://leezhuuuuu.github.io/2025/08/17/%E4%BB%8E%E9%9B%B6%E5%88%B0%E4%B8%80%E6%9E%84%E5%BB%BAAIOps%E6%99%BA%E8%83%BD%E4%BD%93/"},"headline":"从零到一构建AIOps智能体","image":["https://leezhuuuuu.github.io/img/og_image.png"],"datePublished":"2025-08-17T14:00:00.000Z","dateModified":"2025-08-18T14:58:57.839Z","author":{"@type":"Person","name":"leezhuuuuu"},"publisher":{"@type":"Organization","name":"leezhuuuuu's blog","logo":{"@type":"ImageObject","url":"https://avatars.githubusercontent.com/u/178091611?v=4"}},"description":"写在前面：大家好。在近期为期三个月的实习中，我深度参与了大型语言模型（LLM）Agent的探索与实践。这篇文章，我想和大家分享我从零到一构建一个系统级智能Agent框架的心路历程。它不只是一篇技术教程，更是一次关于如何将LLM的强大推理能力，转化为稳定、可靠的工程能力的深度复盘。希望能给同样走在这条路上的你，带来一些启发。   第一部分：问题的本质 —— 我为什么要构建这个框架？ 故事的起点，可"}</script><link rel="canonical" href="https://leezhuuuuu.github.io/2025/08/17/%E4%BB%8E%E9%9B%B6%E5%88%B0%E4%B8%80%E6%9E%84%E5%BB%BAAIOps%E6%99%BA%E8%83%BD%E4%BD%93/"><link rel="icon" href="https://avatars.githubusercontent.com/u/178091611?v=4"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="../../../../css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="../../../../index.html"><img src="https://avatars.githubusercontent.com/u/178091611?v=4" alt="leezhuuuuu&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="../../../../index.html">Home</a><a class="navbar-item" href="../../../../archives">Archives</a><a class="navbar-item" href="../../../../about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2025-08-17T14:00:00.000Z" title="2025/8/17 22:00:00">2025-08-17</time>发表</span><span class="level-item"><time dateTime="2025-08-18T14:58:57.839Z" title="2025/8/18 22:58:57">2025-08-18</time>更新</span><span class="level-item">1 小时读完 (大约10991个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">从零到一构建AIOps智能体</h1><div class="content"><blockquote>
<p><strong>写在前面</strong>：大家好。在近期为期三个月的实习中，我深度参与了大型语言模型（LLM）Agent的探索与实践。这篇文章，我想和大家分享我从零到一构建一个系统级智能Agent框架的心路历程。它不只是一篇技术教程，更是一次关于如何将LLM的强大推理能力，转化为稳定、可靠的工程能力的深度复盘。希望能给同样走在这条路上的你，带来一些启发。</p>
</blockquote>
<hr>
<h2 id="第一部分：问题的本质-——-我为什么要构建这个框架？">第一部分：问题的本质 —— 我为什么要构建这个框架？</h2>
<p>故事的起点，可能和许多投身于AI Agent浪潮的开发者一样，源于一种兴奋与失望交织的复杂感受。</p>
<p>当我第一次看到AutoGPT、BabyAGI等项目演示时，我被它们所展现出的“自主”解决问题的能力深深震撼。一个AI似乎真的能像人一样，接收一个模糊的目标，然后自己上网搜索、编写代码、执行任务。那一刻，我觉得未来已来。</p>
<p>但当兴奋褪去，我开始尝试将这些开源框架应用到严肃的、生产级别的业务场景——比如线上服务的故障排查、性能瓶颈的自动化分析时，最初的“魔法感”很快就被现实的“骨感”所取代。</p>
<p>我至今还记得那个深夜，为了调试一个不断跑偏的Agent，在满屏的日志里大海捞针的挫败感。它的任务本应是分析日志并定位错误根源，但它却在一个无关紧要的警告信息上陷入了死循环，不断地调用工具、分析、然后再次调用同一个工具，耗尽了Token也问不出个所以然。</p>
<p>那一刻我意识到，我遇到的，是所有试图将Agent工程化的开发者都会面临的经典难题：</p>
<ul>
<li><strong>失控的“黑盒”</strong>：Agent的执行过程难以预测，它的行为高度依赖于模型在特定时刻的“灵感”，在需要高可靠性的生产环境中，这几乎是不可接受的。</li>
<li><strong>纠缠的“意大利面”与“上下文污染”</strong>：在简单的Agent实现中，“思考”（规划）、“行动”（调用工具）、“反思”（分析结果）等不同性质的逻辑，都混杂在同一个巨大的Prompt和上下文历史中。我将这种现象称为**“上下文污染”（Context Contamination）**。当上下文变长，LLM就会像一个被灌输了太多杂乱信息的人，开始“迷失”——忘记最初的目标，钻进牛角尖，甚至不知道任务是否已经完成。</li>
<li><strong>僵化的“紧箍咒”</strong>：当我试图对现有框架进行深度定制，让它们更贴合我的业务逻辑时，又发现它们的抽象层次要么太高，要么太低。修改一个小功能，往往需要对核心逻辑进行伤筋动骨的改造。正如我之前对朋友说的：“改到最后，还不如自己重写一个。”</li>
</ul>
<p>这些痛点让我意识到，将LLM Agent从一个有趣的“玩具”变成一个可靠的“工具”，我们缺的不是更强的模型，而是一个全新的<strong>工程化思路</strong>。</p>
<p>我需要一个框架，它首先必须是<strong>白盒的、可控的</strong>；其次，它必须能够从架构层面解决**“上下文污染”<strong>的问题。我需要的不是一个更聪明的“超级大脑”，而是一套能让“大脑”在正确的时间、正确的地点、思考正确问题的</strong>工作流程和约束机制**。</p>
<p>这，就是我决定从零开始构建这个框架的初心：</p>
<blockquote>
<p><strong>以架构设计为手段，进行上下文工程（Context Engineering），从而将LLM强大的推理能力，转化为稳定、可靠的工程能力。</strong></p>
</blockquote>
<p>这，就是我为这匹名为‘LLM’的强大野马，设计、建造并驯服一整套‘缰绳、马鞍与赛道’的故事。</p>
<p>接下来，我将详细阐述指导我构建这个框架的几条核心设计哲学。</p>
<hr>
<h2 id="第二部分：设计的哲学-——-我如何思考Agent的构建">第二部分：设计的哲学 —— 我如何思考Agent的构建</h2>
<p>面对“上下文污染”这个核心敌人，我的答案并非某个单一的算法或模型，而是一套源于经典软件工程、又为LLM Agent时代量身定制的设计哲学。</p>
<p>这套哲学的核心思想，是为了实现最终的目标——<strong>“专事专干”</strong>。</p>
<p>为了达成这个目标，我意识到必须从架构层面进行设计。宏观上，我采用了**“分层与自治”<strong>的结构；为了让这个结构干净地运行，微观上，我规定了</strong>“无状态通信”<strong>的协议；最后，为了将这一切流程串联起来并使其可控可观测，我选择了</strong>“状态驱动”**作为整个系统的运行载体。</p>
<p>这三条原则，层层递进，共同构成了我所设计框架的骨架。</p>
<h3 id="设计一：分层与自治-——-用“专家团队”取代“超级英雄”">设计一：分层与自治 —— 用“专家团队”取代“超级英雄”</h3>
<p>我没有尝试去构建一个无所不能的“超级Agent”，而是借鉴了现实世界中高效专家团队的工作模式，构建了一个分层、自治的系统：</p>
<ul>
<li><strong>总控大脑 (Orchestrator)</strong>：这是系统的“大脑”，一个顶层的Agent。它不执行具体任务，唯一的职责是<strong>理解用户的原始意图、分析当前战况、并将宏大目标分解为一个个清晰、具体、可执行的子任务</strong>。</li>
<li><strong>领域专家 (Specialist Agent)</strong>：这是一系列各有所长的子Agent，比如“日志分析专家”、“性能监控专家”、“知识库检索专家”。它们是系统的“双手”，负责接收“总控大脑”分配的任务卡，并在自己的专业领域内自主完成工作。</li>
</ul>
<p>这个模式的背后，是我对放弃“超级Agent”模式的深度思考。关键在于它通过架构实现了<strong>职责分离</strong>和<strong>上下文隔离</strong>。Orchestrator的上下文中只包含高层战略和历史总结，而Specialist Agent的上下文中只包含当前任务所需的具体信息。这就像将军在指挥部看战略地图，而士兵在前线只关心自己的作战指令，各司其职，互不干扰。</p>
<h3 id="设计二：状态驱动-——-给混乱的思维穿上“紧身衣”">设计二：状态驱动 —— 给混乱的思维穿上“紧身衣”</h3>
<p>Agent的执行过程本质上是一个漫长而充满不确定性的状态流。如果不对状态进行显式管理，整个系统就会变成一匹脱缰的野马。</p>
<p>因此，我选择了一个基于**状态图（StateGraph）**的编排框架作为我项目的基础。这意味着，我可以将整个复杂任务的执行过程，定义成一个严谨的状态机。</p>
<ul>
<li><strong>核心状态对象 (Central State Object)</strong>：我设计了一个核心的状态对象，它像“血液”一样在整个系统中流动，包含了任务在任何时刻的所有快照——从用户请求，到历史记录，再到下一个要调用的Agent。</li>
<li><strong>显式管理的好处</strong>：将状态显式化，带来了巨大的工程化优势。它让Agent的思考过程不再是黑盒，我随时可以“拍快照”来查看当前的状态，这使得<strong>可观测性、可调试性</strong>成为可能。更重要的是，它为系统的<strong>鲁棒性</strong>（从任意检查点恢复任务）奠定了基础。</li>
</ul>
<h3 id="设计三：无状态通信-——-让每一次“协作”都简单纯粹">设计三：无状态通信 —— 让每一次“协作”都简单纯粹</h3>
<p>为了在“总控大脑”和“专家”之间建立最干净的协作关系，我确立了一条铁律：它们之间的通信必须是<strong>无状态的、幂等的</strong>。</p>
<p>这意味着，Orchestrator分配给Specialist Agent的指令（我称之为<code>task_instruction</code>），必须像一张独立的、信息完备的“任务卡”。Specialist Agent仅凭这张卡片，就应该拥有完成任务所需的全部信息，而无需去翻阅之前的任何历史对话。</p>
<p>完成任务后，Specialist Agent也只需返回一张标准的“成果报告”（<code>final_conclusion</code>），说明任务是否成功以及关键结果。</p>
<p>这种设计的好处是巨大的：</p>
<ol>
<li><strong>彻底隔离上下文</strong>：保证了Specialist Agent的工作不会被历史信息干扰。</li>
<li><strong>提高了Agent的复用性</strong>：每个“专家”都可以被即插即用地用于任何符合其能力的环节。</li>
<li><strong>简化了测试</strong>：我可以独立地对每一个“专家”进行单元测试，极大地提高了开发效率和系统稳定性。</li>
</ol>
<blockquote>
<p>这三大设计原则——<strong>分层与自治（宏观结构）、无状态通信（微观协议）、状态驱动（运行载体）</strong>——共同构成了我设计的框架的骨架。它们协同工作，将LLM强大的、但略显混沌的推理能力，约束在一个清晰、稳定、可扩展的工程化体系之中。</p>
</blockquote>
<hr>
<h2 id="第三部分：架构的艺术-——-从思想到代码的桥梁">第三部分：架构的艺术 —— 从思想到代码的桥梁</h2>
<p>空有哲学，没有坚实的架构来承载，一切都是空中楼阁。在这个框架中，我将上述的设计哲学，通过一个强大的图编排工具，翻译成了一套清晰、可执行的架构。</p>
<p>整个系统的核心工作流，是一个由“总控大脑”发起的，经过“专家Agent执行层”处理，再由“总结反思模块”提炼，最终返回给“总控大脑”进行下一轮规划的**“决策-执行-反思”**循环。</p>
<p>这个循环的工作流程如下：</p>
<ol>
<li><strong>决策 (Decision)</strong>：“总控大脑”接收用户请求和历史状态，进行宏观规划，决定下一步应该委派哪个“专家Agent”去执行什么任务，或者判断任务是否已经完成。</li>
<li><strong>路由 (Routing)</strong>：系统根据“总控大脑”的决策，将任务指令路由到指定的“专家Agent”或任务结束节点。</li>
<li><strong>执行 (Execution)</strong>：被选中的“专家Agent”在自己的独立工作空间内，通过“思考-行动-分析”的微循环来完成任务。它可能会多次调用外部工具（如日志查询服务、监控数据接口等）。</li>
<li><strong>总结 (Summarization)</strong>：“专家Agent”完成工作后，其产出的详细报告会被送入“总结反思模块”，提炼成一份高度浓缩的摘要。</li>
<li><strong>反馈 (Feedback)</strong>：这份摘要被更新到“总控大脑”的上下文中，成为它进行下一轮决策的关键依据，从而形成闭环。</li>
</ol>
<p>这套架构的每一处细节，都是我对设计哲学的代码化诠释：</p>
<ul>
<li>
<p><strong>分层与自治的落地</strong>：“总控大脑”和“专家Agent”被明确地分离开。调度逻辑会根据“总控大脑”的输出，决定是调用某一个具体的专家，还是直接走向终点。每个专家Agent都在自己的子图中运行，拥有独立的上下文，完美实现了分层与自治。</p>
</li>
<li>
<p><strong>状态驱动的实现</strong>：整个工作流是围绕一个核心状态对象构建的。这个状态对象就像一个“公文包”，在图中各个节点间传递。“总控大脑”往里放入“任务指令”，“专家Agent”取出指令并放入“执行报告”，“总结模块”再将“执行报告”提炼成“总结陈词”放回去。每一步操作，都是对这个“公文包”内容的读取和修改，整个流程因此变得清晰、可控、可追溯。</p>
</li>
<li>
<p><strong>无状态通信的保障</strong>：“总控大脑”和“专家Agent”之间没有直接的依赖。它们之间通过核心状态对象这个“公文包”解耦，严格遵循了无状态通信的原则。</p>
</li>
</ul>
<p><strong>我为什么选择图编排框架？—— 一场关于“自由”与“约束”的权衡</strong></p>
<p>在技术选型之初，我面临一个关键的选择：是使用像AutoGen这样更高层、开箱即用的框架，还是类似LangGraph这样更底层、更像“乐高积木”的工具集？</p>
<p>前者能让我快速搭建出一个看似强大的多Agent系统，但它的“天花板”也很明显。我必须在框架预设的逻辑内行事，一旦我的需求超出了它的设计范畴，就会陷入无尽的“魔改”困境。</p>
<p>而图编排框架则给了我按自己哲学“从头立法”的最高自由度。它不预设任何高层的Agent交互模型，而是提供最核心的部件——状态（State）、节点（Node）和边（Edge）。它逼着我去思考系统的状态流转，而不是把所有逻辑都塞进一个简单的回调函数里。</p>
<p>这正是我想要的。我相信，<strong>真正的Agent工程化，必须建立在对底层状态流的精确掌控之上</strong>。选择这条路，就是选择了一条更艰难但更正确的道路：用前期的、架构层面的“约束”，来换取后期整个系统行为的“自由”与“可控”。正是这种选择，才让我的“上下文工程”思想得以完美落地。</p>
<hr>
<h2 id="第四部分：智能的涌出（上）——-“总控大脑”的设计与思维链引导">第四部分：智能的涌出（上）—— “总控大脑”的设计与思维链引导</h2>
<p>如果说架构是Agent的骨骼，那么Prompt就是它的灵魂。在我设计的框架中，“总控大脑”的智能，几乎完全是由其背后那个精心设计的系统提示词（System Prompt）所塑造的。</p>
<p>这引出了我在设计中最核心的一个挑战：<strong>如何平衡指令的“精确性”和给予LLM的“自主性”？</strong> 指令太死板，LLM就会退化成一个平庸的<code>if-else</code>机器，丧失智能；指令太模糊，它又会天马行空，导致任务漂移。</p>
<p>我的答案是：<strong>不直接告诉它“做什么”，而是为它“立法”，定义一套清晰的“行为准则”和“工作流程”</strong>。</p>
<p>在“总控大脑”的实现中，我为这个“AI总指挥官”精心设计了它的“世界观”：</p>
<h3 id="1-角色与能力清单：定义“我是谁，我能做什么”">1. 角色与能力清单：定义“我是谁，我能做什么”</h3>
<p>Prompt的第一部分，是为“总控大脑”注入灵魂：</p>
<blockquote>
<p>你是一位顶级的AI任务总指挥官… 你的核心使命是精准地理解用户意图，并以最高效、最全面的方式，调度一组专家级子Agent来解决问题。</p>
</blockquote>
<p>紧接着，我通过一个动态生成的XML片段，向它清晰地展示了它手下所有可用的“专家”和他们各自的能力说明。这就像给一位将军一张兵种图，让他清楚地知道自己手下有步兵、炮兵、还是侦察兵。</p>
<h3 id="2-工作流程立法：定义“我应该如何思考”">2. 工作流程立法：定义“我应该如何思考”</h3>
<p>这是整个Prompt的核心。我没有让“总控大脑”自由发挥，而是为它制定了一套严谨的、必须遵守的思维框架：</p>
<ul>
<li><strong>前提条件检查</strong>：在思考任何问题之前，必须先检查“物料”是否齐全。比如，要诊断服务器问题，IP地址和时间范围是必需的。如果缺失，第一步不是分配任务，而是“要求补充信息”。这避免了大量无效的下游工作。</li>
<li><strong>任务评估</strong>：指令要求它必须先对任务进行分类——是“简单任务”还是“复杂任务”。这个简单的分类，决定了后续的决策模式是“效率优先”还是“全面性优先”。</li>
<li><strong>决策制定</strong>：
<ul>
<li>对于<strong>复杂任务</strong>，我强制它必须先在思考区（<code>&lt;reasoning_for_decision&gt;</code>）制定一个<strong>有序的、多步骤的分析计划</strong>，然后再选择计划中的<strong>第一步</strong>去执行。这有效地将LLM的“发散性思维”引导到了“结构化规划”上。</li>
<li>举个例子，一个平庸的Prompt面对“服务器变慢了”的问题，可能会让LLM直接输出一个模糊的动作，比如“调用性能监控专家”。而我的Prompt会引导它这样思考和输出：
<blockquote>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="tag">&lt;<span class="name">reasoning_for_decision</span>&gt;</span></span><br><span class="line">1. [宏观检查] 首先，使用性能监控专家检查系统整体的CPU、内存、I/O性能，快速判断是否存在资源瓶颈。</span><br><span class="line">2. [日志挖掘] 接着，如果性能指标异常，使用日志分析专家深入分析系统日志，查找与问题时间点相关的具体错误信息。</span><br><span class="line">3. [内核深潜] 最后，如果日志指向了内核层面的问题，使用内核分析专家深入检查内核参数或dmesg记录。</span><br><span class="line"><span class="tag">&lt;/<span class="name">reasoning_for_decision</span>&gt;</span></span><br><span class="line">&gt; <span class="tag">&lt;<span class="name">next_sub_agent_name</span>&gt;</span>性能监控专家<span class="tag">&lt;/<span class="name">next_sub_agent_name</span>&gt;</span></span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li>这个从“直接给答案”到“先给完整计划，再执行第一步”的转变，正是智能涌现的关键。它让Agent的每一步行动，都变得有据可依、有路可循。</li>
<li>对于<strong>任务完成判断</strong>，我给出了极其审慎的指导原则，要求它必须围绕用户的**“核心原始请求”**来判断，并区分了“必须解决的关键问题”和“探索性的优化建议”，避免Agent在不重要的问题上“画蛇添足”。</li>
</ul>
</li>
</ul>
<h3 id="3-输出格式契约：定义“我应该如何表达”">3. 输出格式契约：定义“我应该如何表达”</h3>
<p>最后，我用一个严格的XML结构，约束了“总控大脑”的输出。</p>
<blockquote>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">decision</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">next_sub_agent_name</span>&gt;</span>...<span class="tag">&lt;/<span class="name">next_sub_agent_name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">task_instruction_for_sub_agent</span>&gt;</span>...<span class="tag">&lt;/<span class="name">task_instruction_for_sub_agent</span>&gt;</span></span><br><span class="line">    ...</span><br><span class="line"><span class="tag">&lt;/<span class="name">decision</span>&gt;</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>这个看似简单的约束，其背后是我将Agent的行为**“契约化”<strong>的深度思考。它将LLM不可预测的自然语言输出，转化为了机器可以稳定解析和执行的结构化数据。这使得整个系统的行为变得</strong>可预测、可测试、可调试**，是Agent工程化最关键的一步。</p>
<p>通过这种“立法式”的Prompt Engineering，我并没有扼杀LLM的智能，反而是通过构建一个清晰的思维脚手架，将它的智能引导到了最需要的地方——<strong>进行高质量的规划、决策与推理</strong>，从而实现了“智能的涌现”。</p>
<hr>
<h2 id="第五部分：智能的涌现（下）——-专家Agent的封装与执行">第五部分：智能的涌现（下）—— 专家Agent的封装与执行</h2>
<p>如果说“总控大脑”是运筹帷幄的将军，那么真正深入前线、攻城拔寨的，则是我设计的一个个身怀绝技的“专家Agent”。在这一部分，我将以一个典型的“日志分析专家”为例，看看我是如何将领域知识封装起来，并让它在自己的“一亩三分地”里，高效地完成将军下达的作战任务的。</p>
<h3 id="1-知识的封装：一个“日志专家”的自我修养">1. 知识的封装：一个“日志专家”的自我修养</h3>
<p>在我设计的框架中，每一个专家Agent都是一个独立的、可复用的“黑盒”。“日志分析专家”将所有关于“如何分析日志”的知识，都封装在了自己的内部。它遵循一套标准的接口：接收一个<code>task_instruction</code>，返回一个<code>final_conclusion</code>。</p>
<p>这种封装带来了巨大的好处：“总控大脑”在分配任务时，完全不需要知道“日志分析专家”具体会用<code>grep</code>还是<code>awk</code>，它只需要知道“日志分析专家”能完成“日志分析”这个任务就够了。这使得整个系统的复杂性被有效控制，每一层都只关心自己的职责。</p>
<h3 id="2-内部的“微型ReAct循环”：专家的独立思考">2. 内部的“微型ReAct循环”：专家的独立思考</h3>
<p>“日志分析专家”的内部，并非一个简单的“输入-输出”函数，而是一个<strong>小而完整的“微型ReAct循环”</strong>。我让它由三个核心节点构成一个状态图，不断地进行“思考-行动-分析”的迭代，直到任务完成。</p>
<ol>
<li>
<p><strong>思考节点 (PlanNode)</strong>：这是“日志分析专家”自己的“大脑”。它接收到“总控大脑”的任务后，会基于一个为“日志排错专家”量身定制的Prompt进行思考。它的任务很纯粹：分析当前已有的日志信息，然后决策下一步是“调用一个日志分析工具”，还是“信息足够，可以下结论了”。</p>
</li>
<li>
<p><strong>行动节点 (ToolNode)</strong>：这是“日志分析专家”的“双手”。它忠实地执行“思考节点”的决策。这里隐藏着一个关键的、体现我工程化思想的设计决策：<strong>工具的服务化</strong>。“行动节点”并非直接调用某个本地的Python函数，而是通过一个统一的加载器，去调用标准化的<strong>外部工具服务</strong>。</p>
<p>我为什么要做这层抽象？因为这实现了<strong>Agent的逻辑</strong>与<strong>工具的生命周期</strong>的彻底解耦。工具服务可以被独立部署、迭代、扩缩容，甚至可以用完全不同的技术栈来实现。今天“日志分析专家”调用的日志分析工具是用Python写的，明天我完全可以无缝切换到一个性能更强的、用Go编写的服务，而Agent的代码一行都不需要改。</p>
<p>这个设计，让我构建的不仅仅是一个单体的应用，而是一个具备了**可扩展的“Agent平台”**的雏形。</p>
</li>
<li>
<p><strong>分析/反思节点 (AnalyzeNode)</strong>：当工具执行完毕，原始的、混杂的输出结果（比如一大段日志文本）会被送到“分析/反思节点”。它负责将这些“脏数据”，提炼成对LLM友好的、结构化的“分析摘要”。这个摘要会成为下一轮“思考节点”思考时的关键输入。<strong>这是系统“反思”能力的又一体现</strong>，确保Agent的每一次决策，都是基于对已有事实的深刻理解。</p>
</li>
</ol>
<p>这个“<code>Plan</code> -&gt; <code>Tool</code> -&gt; <code>Analyze</code>”的循环，会一直进行下去，直到“思考节点”认为它已经找到了问题的根源，或者达到了设定的最大迭代次数。届时，它会跳出循环，形成最终的<code>final_conclusion</code>，向上层汇报。</p>
<p>通过这种方式，我将一个宏大的、复杂的任务，分解成了“总控大脑”的高层战略规划，和每个专家Agent内部的、聚焦于自身领域的、可控的“微型ReAct循环”。智能，正是在这样一层层的、结构化的涌现中，被引导、被塑造、被工程化。</p>
<hr>
<h2 id="第六部分：格式即认知-——-我为什么选择XML作为Agent的“官方语言”">第六部分：格式即认知 —— 我为什么选择XML作为Agent的“官方语言”</h2>
<p>在详细了解了框架的协作模式后，细心的读者可能会注意到一个“反常识”的技术选择：在JSON大行其道的今天，为什么我设计的Agent内部“沟通语言”，选择了看似“复古”的XML？</p>
<p>答案在于，我必须从“机器效率”的传统视角，转向“模型认知效率”的全新视角来审视这个问题。因为，与Agent交互的数据格式，不仅仅是数据的容器，更是塑造其思维过程的“框架”。</p>
<h3 id="1-XML作为“低认知负荷”的思维脚手架">1. XML作为“低认知负荷”的思维脚手架</h3>
<p>大型语言模型的“注意力”是一种有限资源。不佳的数据格式会带来高昂的“认知负荷”。</p>
<p>JSON严格的、符号密集的语法（无处不在的<code>&quot;</code>、<code>,</code>、<code>&#123;&#125;</code>）会强制模型分配大量注意力去维持语法的正确性，这是一种高昂的“语法税”。对于需要深度、连贯推理的任务，这种“语法税”会严重干扰其主线思考，形成“认知枷锁”，就像一个人一边解复杂的数学题，一边还被要求严格按照诗歌的格律来写步骤一样。</p>
<p>相比之下，XML的标签（如<code>&lt;reasoning&gt;</code>, <code>&lt;tool_name&gt;</code>）本身就是自然语言，它们为模型的思考过程提供了明确的、语义化的“容器”，是一个完美的“思维脚手架”。这与“思维链 (Chain of Thought)”的理念不谋而合，通过结构化的标签，模型可以更从容地展开自己的推理步骤，实现“先思考，再表达”，而不是将思考和表达混为一谈。</p>
<p>让我们通过一个例子直观地感受一下“信噪比”的差异：</p>
<ul>
<li><strong>JSON (低信噪比)</strong>: <code>&#123;&quot;decision&quot;: &#123;&quot;next_sub_agent_name&quot;: &quot;LogAgent&quot;&#125;&#125;</code></li>
<li><strong>XML (高信噪比)</strong>: <code>&lt;decision&gt;&lt;next_sub_agent_name&gt;LogAgent&lt;/next_sub_agent_name&gt;&lt;/decision&gt;</code></li>
</ul>
<p>在XML中，<code>decision</code>和<code>tool_name</code>这些承载真实语义的“信号”词元占主导地位。而在JSON中，模型则需要在一堆<code>&quot;</code>、<code>&#123;&#125;</code>等“噪声”符号之间跳跃来拼凑语义。XML的结构，天然地为LLM的思考过程提供了“低认知负荷、高信噪比”的优越环境。</p>
<h3 id="2-CDATA作为“语义保真”的保护区">2. CDATA作为“语义保真”的保护区</h3>
<p>我设计的AIOps Agent，经常需要处理包含大量特殊字符的代码或Shell命令。</p>
<ul>
<li><strong>JSON的困境</strong>: 必须通过大量转义（如<code>\n</code>, <code>\&quot;</code>）来处理这些内容，这个过程会破坏内容的内部结构，造成“语义降维”。</li>
<li><strong>XML的优势</strong>: <code>&lt;![CDATA[...]]&gt;</code>区块像一个“语义保护区”，可以原封不动地保留复杂内容的原始语义和结构，这对于需要高保真传递指令和代码的工程化Agent至关重要。</li>
</ul>
<h3 id="3-一个深思熟虑的“以模型为中心”的决策">3. 一个深思熟虑的“以模型为中心”的决策</h3>
<p>所以，我选择XML，并非技术上的怀旧，而是一个深刻的、‘以模型为中心’的设计决策。我相信，在构建以推理为核心的复杂Agent系统时，<strong>优化模型的‘思考环境’，比优化机器的‘解析环境’，具有更高的优先级。</strong> 为模型选择一种更符合其认知范式的“官方语言”，是将其能力从“概率计算”推向“可靠推理”的关键一步。</p>
<hr>
<h2 id="第七部分：对标准RAG范式的优化与思考：从“相关性”到“效用性”">第七部分：对标准RAG范式的优化与思考：从“相关性”到“效用性”</h2>
<p>在我构建的知识库检索模块中，我没有止步于业界标准的“检索-重排（Rerank）”范式。在项目初期的实践中，我敏锐地发现了一个核心问题：由标准<code>rerank</code>模型筛选出的“语义最相关”的知识，在多步骤的复杂任务中，往往并非**“对下一步决策最有用”**的知识。</p>
<p>举个例子：Agent正在处理“服务器变慢了”的任务，并且已经通过性能监控专家定位到是“CPU使用率过高”。此时，知识库检索模块被调用以寻求解决方案。<code>rerank</code>模型很可能会推荐一篇标题为“如何排查服务器慢的通用步骤”的高度相关文档。但这篇文档，对于已经进入“CPU过高”这个具体环节的Agent来说，是**“正确的废话”**。Agent此刻真正需要的，是一篇深入讲解“如何用perf工具分析进程CPU占用”的文档，即使它与用户的原始查询“服务器变慢了”在字面上的相关性并不高。</p>
<p>认识到这一点后，我主导了一次重要的技术迭代。我判断，判断知识在特定任务上下文中的“效用性”，本身就是一个高级的认知任务，应当交由最强大的认知引擎（即LLM本身）来完成，而不是一个只懂语义相关性的小模型。</p>
<p>基于这个思考，我设计并实现了一套全新的“两阶段”知识筛选流程：</p>
<ul>
<li>
<p><strong>第一阶段 (海选)</strong>：利用传统向量及关键词技术，高效、广泛地召回所有<strong>可能相关</strong>的文档，确保候选集的全面性。</p>
</li>
<li>
<p><strong>第二阶段 (精炼)</strong>：这是我设计的核心。我构建了一个由LLM驱动的筛选节点，通过精心设计的Prompt，将<strong>当前任务的完整上下文</strong>（比如“已经发现CPU过高”）注入其中。我让LLM的判断基准从“与原始查询相关”，转变为“对解决当前问题有用”。同时，我强制LLM必须在<code>&lt;thinking&gt;</code>标签中，清晰地阐述其筛选理由，使得这个“精炼”过程不再是黑盒。值得注意的是，我不仅要求LLM给出思考过程，更在提示词的工作流程中，严格规定了它必须<strong>先输出<code>&lt;thinking&gt;</code>，再输出<code>&lt;ids&gt;</code></strong>。这并非一个随意的格式要求，而是一种**“强制的思维链引导”**。它能更大概率地引导模型真正地、一步步地进行逻辑推理，并将这个真实的推理过程记录下来，而不是先给出一个直觉性的结论，再“事后编造”一个看似合理的理由。</p>
</li>
</ul>
<p>通过这次迭代，我将模块的核心能力从“信息检索”提升到了“知识应用”的层面。这个过程不仅展现了我对RAG技术的深刻理解，更体现了我敢于挑战业界标准范式、追求更优解决方案的工程精神与创新能力。</p>
<hr>
<h2 id="第八部分：能力的扩展-——-为框架注入新的“灵魂”">第八部分：能力的扩展 —— 为框架注入新的“灵魂”</h2>
<p>一个好的框架，不仅要自身强大，更要易于扩展。在设计的最初，我就遵循了软件工程的经典原则——<strong>“开放/封闭原则”</strong>（对扩展开放，对修改封闭）。</p>
<p>这意味着，当我想要为框架增添一项全新的能力——比如一个“数据库操作专家”或者一个“代码生成专家”——完全不需要去修改“总控大脑”或任何核心的工作流代码。只需要像拼乐高一样，拼装一个新的Agent，然后“注册”到系统中，“总控大脑”就能自动识别并开始调度它。</p>
<p>为了实现这一点，我设计了一套简洁的插件化注册流程：</p>
<h3 id="第一步：定义“能力”与“记忆”-Tools-State">第一步：定义“能力”与“记忆” (Tools &amp; State)</h3>
<p>首先，为新Agent定义它能做什么（Tools）和它需要记住什么（State）。在我的设计里，State是一个简单的字典结构，用于Agent内部流转；Tools则是一系列封装好的Python函数，并推荐将其部署为独立的微服务，以实现更好的解耦。</p>
<h3 id="第二步：设计“工作流”-Nodes">第二步：设计“工作流” (Nodes)</h3>
<p>接下来，设计Agent内部的工作流程。对于大多数ReAct模式的Agent来说，我使其可以复用经典的“<code>Plan</code> -&gt; <code>Tool</code> -&gt; <code>Analyze</code>”三节点模式。开发者只需要创建这些节点的类，并根据业务逻辑，调整它们各自的Prompt即可。例如，在一个天气查询专家的<code>PlanNode</code>中，Prompt就会被设定为：“你是一个天气查询专家，你的目标是根据用户输入，调用工具获取天气信息…”</p>
<h3 id="第三步：组装并“注册”-Agent">第三步：组装并“注册” (Agent)</h3>
<p>最后一步，是将上面定义的State, Tools, Nodes组装成一个完整的图。然后，通过我设计的统一注册接口，将这个新Agent的定义和能力描述注入到“总控大脑”的配置中。</p>
<p>完成了！就是这么简单。当框架重新启动，“总控大脑”在思考时，它的“可用专家列表”里就会自动出现新的专家以及它的能力描述。当用户提出相关的请求时，“总控大脑”就会“想”到这位新专家，并把任务分配给它。</p>
<p>这种插件式的设计，让框架拥有了无限的成长潜力。它就像一个智能的“操作系统”，而开发者，则可以不断地为它开发新的“App”（专家Agent），让它的能力边界不断扩展。</p>
<hr>
<h2 id="第九部分：总结与洞见-——-我对Agent工程化的思考">第九部分：总结与洞见 —— 我对Agent工程化的思考</h2>
<p>行文至此，我构建这个框架的核心思想与实现之旅已近尾声。回望整个过程，我想用一句话来总结我的核心思考：</p>
<blockquote>
<p><strong>以架构设计为手段，进行上下文工程，从而将LLM强大的推理能力，转化为稳定、可靠的工程能力。</strong></p>
</blockquote>
<p>LLM的能力是惊人的，但它本质上是一个“概率机器”，而非“逻辑机器”。我们不能期望它在所有情况下都表现完美。作为工程师，我的职责，正是要构建一个足够健通的“容器”和“护栏”，让这匹强大的“野马”能在我们设定的赛道里，跑得又快又稳。</p>
<p>在结束之前，我想分享的，是我认为Agent开发最重要的一个转向：</p>
<blockquote>
<p><strong>我坚信，我们必须停止将其视为一个单纯的“模型应用”问题，而开始将其视为一个严肃的“软件工程”问题。</strong></p>
</blockquote>
<p>我所有的设计哲学和思考，最终都指向了这一点。</p>
<h3 id="洞见一：Agent的“异常处理”-——-拥抱并结构化失败">洞见一：Agent的“异常处理” —— 拥抱并结构化失败</h3>
<p>在传统软件工程中，我们用<code>try-catch</code>来处理异常。而在Agent的世界里，“失败”是一种信息，而非异常。我所设计框架的独特之处，在于它将**“失败”视为一种结构化的、有价值的数据**来驱动流程。“总结反思模块”生成的“失败报告”，就是Agent世界的“结构化异常对象”。这使得“总控大脑”可以像一个高级的异常处理器一样，基于失败的类型、来源等信息，做出重试、切换策略等更智能的决策。</p>
<h3 id="洞见二：Agent的“接口设计”-——-从函数到服务的进化">洞见二：Agent的“接口设计” —— 从函数到服务的进化</h3>
<p>我们为Agent设计工具，本质上就是在为它设计与世界交互的“API”。在实践中，我发现将工具仅仅实现为本地函数，会将工具的生命周期和Agent的生命周期紧紧地耦合在一起，这非常痛苦。</p>
<p>这促使我对工具的设计进行了更深层次的思考，并最终走向了**“标准化的工具服务”**。</p>
<p>其核心，是将工具从Agent框架中彻底剥离，使其成为遵循统一协议的、可被独立部署和维护的外部服务。这背后是关于**“生命周期解耦”**的深度思考。它带来了巨大的工程化优势：</p>
<ul>
<li><strong>独立迭代</strong>：负责不同工具的团队可以随时更新他们的服务，而无需通知和改动Agent的任何一行代码。</li>
<li><strong>异构实现</strong>：工具服务可以用最适合它的技术栈来实现（Python, Go, Java…），只要它遵守协议即可。</li>
<li><strong>清晰的权责边界</strong>：Agent的开发者专注于“思考链”的构建，工具的开发者专注于业务逻辑的实现，权责分明，协作高效。</li>
</ul>
<p>所以，在这个项目中，我对“接口设计”的回答是：<strong>不仅要设计“粗粒度”的接口，更要设计“服务化”的接口。</strong> 这是将Agent从一个单体应用，推向一个可扩展、可维护的“Agent平台”的关键一步。</p>
<h3 id="洞见三：Agent的“需求边界”-——-明确“Copilot”定位">洞见三：Agent的“需求边界” —— 明确“Copilot”定位</h3>
<p>任何一个成功的软件项目，都有清晰的需求边界。对于Agent而言，更是如此。我给这个框架的定位非常明确：<strong>它是一个强大的“Copilot”，一个赋能人类专家的“超级副驾”，而不是一个试图取代专家的全自动系统。</strong></p>
<p>它的最终报告是给“人”看的，最终的决策权也掌握在“人”的手中。这个定位，就是我为这个“软件项目”划定的核心需求边界。它既是一个务实的工程决策，也为系统的未来（比如，在未来版本中引入人机交互节点让协作更顺畅）留下了广阔的迭代空间。</p>
<h3 id="洞见四：选择“艰难而正确”的道路-——-质量优先的设计哲学">洞见四：选择“艰难而正确”的道路 —— 质量优先的设计哲学</h3>
<p>读到这里，相信读者已经能感受到，我设计的这套分层、自治、多节点的复杂架构，并非没有代价。它带来了更高的开发成本、更长的模型推理链条，以及在单次任务上更高的延迟和Token消耗。</p>
<p>然而，这种复杂性是我主动选择的结果。在项目立项之初，我就确立了**“质量优先于一切”**的核心设计哲学。我坚信，在Agent技术的工程化初期，首要任务是将Agent的能力下限提到足够高，确保它在核心场景下是可靠、可信赖、可被交付的。</p>
<p>一个即使秒级响应、成本极低但结果不可靠的Agent，最终只会被用户抛弃。而一个虽然“慢”、虽然“贵”，但总能给出专业、深入、可信赖结果的Agent，才会真正成为专家手中的“工具”，而非昙花一现的“玩具”。</p>
<p>先追求极致的质量和可靠性，再在这个坚实的基础上，去进行速度和成本的优化——这是我为这个项目选择的“艰难而正确”的道路。我的目标，不是做出一个“看起来似乎有用”的Agent，而是打造一个在真实世界中“真正有用”的Agent。</p>
<hr>
<p>在结束之前，我想分享一个思考。在AI Agent这个日新月异的领域，真正的护城河，并非某个具体的代码实现，而是通往这些设计决策背后，那个充满试错、反思与自我否定的**“动态过程”**。</p>
<p>我希望通过这篇长文与大家分享的，正是这个过程。我相信，在Agent工程化这片广阔的无人区，真正的进步，源于每一次勇敢的探索、每一次对“标准范式”的真诚反思，以及每一次失败后沉淀下来的、对问题本质更深刻的认知。</p>
<p>感谢你的阅读。构建这个框架的旅程，也是我个人对于AI Agent工程化思考不断加深的旅程。这个领域还很新，充满了未知与挑战，但也正因如此，才格外激动人心。希望我的分享能为你带来启发，也期待在探索未来的路上，与你同行。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>从零到一构建AIOps智能体</p><p><a href="https://leezhuuuuu.github.io/2025/08/17/从零到一构建AIOps智能体/">https://leezhuuuuu.github.io/2025/08/17/从零到一构建AIOps智能体/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>leezhuuuuu</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2025-08-17</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2025-08-18</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="../LLM-Agent%E8%AE%A4%E7%9F%A5%E5%B7%A5%E7%A8%8B%E5%AD%A6%E6%8A%A5%E5%91%8A%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%E6%99%BA%E8%83%BD/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">LLM Agent认知工程学报告：数据格式如何定义模型智能</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="../../../01/17/%E5%85%B3%E4%BA%8E%E4%B8%80%E4%B8%AA%E9%80%9A%E7%94%A8agent-Mindhub%E7%9A%84%E6%9E%84%E6%80%9D/"><span class="level-item">关于一个通用agent-Mindhub的构思</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://avatars.githubusercontent.com/u/178091611?v=4" alt="leezhuuuuu"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">leezhuuuuu</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="../../../../archives/"><p class="title">9</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="../../../../categories/"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="../../../../tags/"><p class="title">5</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/leezhuuuuu" target="_blank" rel="me noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/leezhuuuuu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="E-mail" href="../../../../mailto:me@leezhu.cn"><i class="fas fa-envelope"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="../../../../categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">知识点学习</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="../../../../categories/%E7%BB%8F%E9%AA%8C%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"><span class="level-start"><span class="level-item">经验技术分享</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="../../../../categories/%E7%BB%8F%E9%AA%8C%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/%E5%AD%A6%E6%9C%AF/"><span class="level-start"><span class="level-item">学术</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="../../../../categories/%E7%BB%8F%E9%AA%8C%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/%E5%AD%A6%E6%9C%AF/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-08-17T15:05:26.000Z">2025-08-17</time></p><p class="title"><a href="../LLM-Agent%E8%AE%A4%E7%9F%A5%E5%B7%A5%E7%A8%8B%E5%AD%A6%E6%8A%A5%E5%91%8A%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%E6%99%BA%E8%83%BD/">LLM Agent认知工程学报告：数据格式如何定义模型智能</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-08-17T14:00:00.000Z">2025-08-17</time></p><p class="title"><a href="">从零到一构建AIOps智能体</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-01-17T07:11:12.000Z">2025-01-17</time></p><p class="title"><a href="../../../01/17/%E5%85%B3%E4%BA%8E%E4%B8%80%E4%B8%AA%E9%80%9A%E7%94%A8agent-Mindhub%E7%9A%84%E6%9E%84%E6%80%9D/">关于一个通用agent-Mindhub的构思</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-13T01:48:02.000Z">2024-11-13</time></p><p class="title"><a href="../../../../2024/11/13/%E5%A2%9E%E5%BC%BA%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%A1%E7%AE%97%E8%83%BD%E5%8A%9B%E7%9A%84%E4%B8%80%E7%A7%8D%E6%96%B9%E6%B3%95%EF%BC%9A%E5%9F%BA%E4%BA%8E%E6%9A%82%E5%81%9C%E6%8E%A8%E7%90%86%E7%9A%84%E5%A4%96%E9%83%A8%E8%AE%A1%E7%AE%97/">增强语言模型计算能力的一种方法：基于暂停推理的外部计算</a></p><p class="categories"><a href="../../../../categories/%E7%BB%8F%E9%AA%8C%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/">经验技术分享</a> / <a href="../../../../categories/%E7%BB%8F%E9%AA%8C%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/%E5%AD%A6%E6%9C%AF/">学术</a> / <a href="../../../../categories/%E7%BB%8F%E9%AA%8C%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/%E5%AD%A6%E6%9C%AF/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-08T04:39:50.000Z">2024-10-08</time></p><p class="title"><a href="../../../../2024/10/08/%E5%9F%BA%E4%BA%8E%E8%B0%83%E5%BA%A6%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A3%E7%B3%BB%E7%BB%9F/">基于调度员的数学问题求解系统</a></p><p class="categories"><a href="../../../../categories/%E7%BB%8F%E9%AA%8C%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/">经验技术分享</a> / <a href="../../../../categories/%E7%BB%8F%E9%AA%8C%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/%E5%AD%A6%E6%9C%AF/">学术</a> / <a href="../../../../categories/%E7%BB%8F%E9%AA%8C%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/%E5%AD%A6%E6%9C%AF/NLP/">NLP</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="../../../../archives/2025/08/"><span class="level-start"><span class="level-item">八月 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="../../../../archives/2025/01/"><span class="level-start"><span class="level-item">一月 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="../../../../archives/2024/11/"><span class="level-start"><span class="level-item">十一月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="../../../../archives/2024/10/"><span class="level-start"><span class="level-item">十月 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="../../../../archives/2023/12/"><span class="level-start"><span class="level-item">十二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="../../../../tags/NLP/"><span class="tag">NLP</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="../../../../tags/%E6%95%B0%E5%AD%A6/"><span class="tag">数学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="../../../../tags/%E7%94%B5%E7%A3%81%E5%9C%BA/"><span class="tag">电磁场</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="../../../../tags/%E7%9F%A5%E8%AF%86%E7%82%B9/"><span class="tag">知识点</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="../../../../tags/%E7%BB%8F%E9%AA%8C%E6%8A%80%E6%9C%AF/"><span class="tag">经验技术</span><span class="tag">4</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="../../../../index.html"><img src="https://avatars.githubusercontent.com/u/178091611?v=4" alt="leezhuuuuu&#039;s blog" height="28"></a><p class="is-size-7"><span>&copy; 2025 leezhuuuuu</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="../../../../js/column.js"></script><script src="../../../../js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="../../../../js/back_to_top.js" defer></script><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script src="../../../../js/pjax.js"></script><!--!--><script data-pjax src="../../../../js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="../../../../js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"../../../../content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>